{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General approach to kNN\n",
    "\n",
    "1. Collect: any method\n",
    "2. Prepare: numeric values are need for a distance calculation. A structured data format is best.\n",
    "3. Anayze: any method\n",
    "4. Train: does not apply to the kNN algorithm\n",
    "5. Test: calculate the error rate\n",
    "6. Use: This application needs to get some input data and output structure numeric values. Next, the application run the kNN algorithm on this input data and determines whitch class the input data should belong to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Collect: \n",
    "Tengo el fichero train.csv, test.csv y gender_submission.csv (este último para ver el formato del fichero que se envía)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare\n",
    "Hay que preparar los datos primero del fichero de training y luego del de test.\n",
    "* Extraer las labels.\n",
    "* Transformar los valores no numericos en valores numéricos.\n",
    "* Tratar los valores nulos.\n",
    "* Establecer valores entre 0 y 1\n",
    "\n",
    "Por simplificar obviaré el control de errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def saveFile(filename, data):\n",
    "    output = open(filename, 'wb')\n",
    "    pickle.dump(data, output)\n",
    "    output.close()\n",
    "    \n",
    "def loadFile(filename):\n",
    "    pkl_file = open(filename, 'rb')\n",
    "\n",
    "    data = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def loadData(filename):\n",
    "    data = loadFile(filename + '_data.txt')\n",
    "    labels = loadFile(filename + '_labels.txt')\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "MAX_CLASS = 3 # Max value of passae Class\n",
    "MAX_AGE = 100\n",
    "MAX_SIBLINGS = 10\n",
    "MAX_PARENTS = 10\n",
    "MAX_TICKET = 3101317.0\n",
    "MAX_FARE = 512.3292\n",
    "MAX_CABIN = 148.0\n",
    "\n",
    "def removeName(line):\n",
    "    return re.sub('\"(.*?)\",','', line)\n",
    "\n",
    "def normalizeClass(classNumber):\n",
    "    return (float(classNumber) - 1.0)/ (MAX_CLASS -1)\n",
    "\n",
    "def normalizeSex(sex):\n",
    "    sexNormalizedValues = { \"male\" : 0.5, \"female\" : 1}\n",
    "    \n",
    "    if sex in sexNormalizedValues:\n",
    "        return sexNormalizedValues[sex]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def normalizeAge(age):\n",
    "    if not age:\n",
    "        return 0\n",
    "    else:\n",
    "        return float(age) / MAX_AGE\n",
    "    \n",
    "def normalizeNumberOfSiblings(siblings):\n",
    "    if not siblings:\n",
    "        return 0\n",
    "    else:\n",
    "        return float(siblings) / MAX_SIBLINGS\n",
    "\n",
    "def normalizeNumberOfParents(parents):\n",
    "    if not parents:\n",
    "        return 0\n",
    "    else:\n",
    "        return float(parents) / MAX_PARENTS\n",
    "    \n",
    "def normalizePrefixTicket(ticket):\n",
    "    prefixes = { 'A/5' : 0.01, 'A/5.' : 0.01, 'A./5.': 0.01, 'A.5.' : 0.01, 'PC' : 0.02, 'STON/O2.' : 0.03, 'PP' : 0.04, 'C.A.' : 0.05, 'CA' : 0.05 , 'CA.' : 0.05, 'SC/Paris' : 0.06, 'SC/PARIS' : 0.06, 'S.C./PARIS' : 0.06, 'S.C./A.4.' : 0.07, 'A/4.' : 0.08, 'A4.' : 0.08, 'A/4' : 0.08, 'S.P.' : 0.09, 'S.O.C.' : 0.10, 'SO/C' : 0.10, 'W./C.' : 0.11, 'W/C' : 0.11, 'SOTON/OQ' : 0.12, 'SOTON/O.Q.' : 0.12, 'W.E.P.' : 0.13, 'WE/P' : 0.13, 'STON/O' : 0.14, 'C' : 0.15, 'S.O.P.' : 0.16, 'Fa' : 0.17, 'F.C.C.' : 0.18, 'SW/PP' : 0.19, 'S.W./PP' : 0.19, 'SCO/W' : 0.20, 'P/PP' : 0.21, 'SC': 0.22, 'SC/AH' : 0.23, 'A/S': 0.24, 'S.O./P.P.' : 0.25, 'F.C.' : 0.26, 'SOTON/O2' : 0.27, 'C.A./SOTON' : 0.28 }\n",
    "\n",
    "    ticketSplitedData = ticket.split(' ')\n",
    "    if len(ticketSplitedData) > 1:\n",
    "        ticketPrefix = ticketSplitedData[0]\n",
    "        if ticketPrefix in prefixes:\n",
    "            return prefixes[ticketPrefix]\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def normalizeTicketNumber(ticket):\n",
    "    return getTicketNumber(ticket) / MAX_TICKET\n",
    "\n",
    "def getTicketNumber(ticket):\n",
    "    ticketSplitedData = ticket.split(' ')\n",
    "    \n",
    "    if len(ticketSplitedData) == 1:\n",
    "        if ticket == 'LINE':\n",
    "            return 0\n",
    "        else:\n",
    "            return float(ticket)\n",
    "    else:\n",
    "        return float(ticketSplitedData[len(ticketSplitedData)-1]) \n",
    "    \n",
    "def normalizeFare(fare):\n",
    "    if len(fare) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return float(fare) / MAX_FARE\n",
    "    \n",
    "def normalizeCabinPrefix(cabin):\n",
    "    prefixes = { 'A' : 0.1, 'B' : 0.2, 'C': 0.3, 'D' : 0.4, 'E' : 0.5, 'F' : 0.6, 'G' : 0.7, 'T': 0.8 }\n",
    "    \n",
    "    if len(cabin) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        cabinSplitedData = cabin.split(' ')\n",
    "    \n",
    "        if len(cabinSplitedData) == 1:\n",
    "            return prefixes[cabin[0]]\n",
    "        else:\n",
    "            return prefixes[cabinSplitedData[0][0]]\n",
    "        \n",
    "def normalizeCabinNumber(cabin):\n",
    "    if len(cabin) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        cabinNumber = getCabinNumber(cabin)\n",
    "        if cabinNumber == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return cabinNumber / MAX_CABIN\n",
    "        \n",
    "def getCabinNumber(cabin):\n",
    "    cabinSplitedData = cabin.split(' ')\n",
    "    \n",
    "    if len(cabinSplitedData) == 1:\n",
    "        if len(cabin) == 1:\n",
    "            return 0\n",
    "        else:\n",
    "            return float(cabin[1:])\n",
    "    else: \n",
    "        if len(cabinSplitedData[0]) == 1:\n",
    "            return 0\n",
    "        else:\n",
    "            return float(cabinSplitedData[0][1:])\n",
    "\n",
    "def normalizeEmbarked(embarked):\n",
    "    embarkedOptions = { '' : 0, 'C' : 0.25, 'Q': 0.5, 'S' : 1}\n",
    "    \n",
    "    return embarkedOptions[embarked]\n",
    "        \n",
    "def processTrainingFile(filename, test):\n",
    "    file = open(filename)\n",
    "    \n",
    "    labels = []\n",
    "    trainingData = []\n",
    "    \n",
    "    # Leer fichero linea a linea\n",
    "    header = True\n",
    "    for line in file.readlines():\n",
    "        if not header:\n",
    "            line = removeName(line)\n",
    " \n",
    "            if test:\n",
    "                line = 'fake,' + line\n",
    "            \n",
    "            lineValueList = line.strip().split(',')\n",
    "    \n",
    "            if not test:\n",
    "                labels.append(lineValueList[1])\n",
    "            \n",
    "            treatedData = []\n",
    "            treatedData.append(normalizeClass(lineValueList[2]))\n",
    "            treatedData.append(normalizeSex(lineValueList[3]))\n",
    "            treatedData.append(normalizeAge(lineValueList[4]))\n",
    "            treatedData.append(normalizeNumberOfSiblings(lineValueList[5]))\n",
    "            treatedData.append(normalizeNumberOfParents(lineValueList[6]))\n",
    "            treatedData.append(normalizePrefixTicket(lineValueList[7]))\n",
    "            treatedData.append(normalizeTicketNumber(lineValueList[7]))\n",
    "            treatedData.append(normalizeFare(lineValueList[8]))\n",
    "            treatedData.append(normalizeCabinPrefix(lineValueList[9]))\n",
    "            treatedData.append(normalizeCabinNumber(lineValueList[9]))\n",
    "            treatedData.append(normalizeEmbarked(lineValueList[10]))\n",
    "            \n",
    "            trainingData.append(treatedData)\n",
    "        else:\n",
    "            header = False\n",
    "                \n",
    "    # Guardar el fichero con las transformaciones\n",
    "    saveFile(filename + '_data.txt', trainingData)\n",
    "    # Guardar el fichero con las labels\n",
    "    saveFile(filename + '_labels.txt', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "processTrainingFile('titanic/train.csv', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processTrainingFile('titanic/test.csv', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideTrainingFile(filename, testPercentage):\n",
    "    # Lee los ficheros, calcula el numero necesario de registros\n",
    "    data, labels = loadData(filename)\n",
    "    testItems = int(len(data) * testPercentage)\n",
    "\n",
    "    # Divide el vector y las matrices\n",
    "    data_training = data[testItems:]\n",
    "    label_training = data[testItems:]\n",
    "    data_test = data[:testItems]\n",
    "    label_test = labels[:testItems]\n",
    "\n",
    "    \n",
    "    # Guarda en ficheros adicionales\n",
    "    saveFile(filename + '.data_training', data_training)\n",
    "    saveFile(filename + '.label_training', label_training)\n",
    "    saveFile(filename + '.data_test', data_test)\n",
    "    saveFile(filename + '.label_test', label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "divideTrainingFile('titanic/train.csv', 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anayze: any method\n",
    "Necesitaria ver formas de analizar estos datos. Siguiendo con los libros o quizas con cursos de formación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train: does not apply to the kNN algorithm\n",
    "No hay training, sino directamente el algoritmo. En este caso se trata de una modificación del kNN que calcula las distancias para que calcule para cualquier profundidad de los vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import operator\n",
    "\n",
    "def classify0(inputVector, trainingDataSet, trainingLabels, k):\n",
    "    # inX es un vector\n",
    "    # dataSet es una matriz\n",
    "    # labels es un vector, el numero de elementos de labels = numero de filas de dataset\n",
    "    # k es un entero menor que el numero de filas de dataset\n",
    "    \n",
    "    # CALCULANDO UNA MATRIZ DE DISTANCIAS ENTRE inX Y LOS PUNTOS EXISTENTES EN dataSet\n",
    "    # para ello se calcula la distancia Euclidiana con cada uno de los puntos\n",
    "    # La funcion 'tile' repite el vector inX en una matriz de dataSetSize filas y 1 columna\n",
    "    # A esa matriz se le resta el data set\n",
    "    trainingDataSetSize = trainingDataSet.shape[0]\n",
    "    \n",
    "    differentialMatrix = np.tile(inputVector, (trainingDataSetSize,1)) - trainingDataSet\n",
    "    squaredDifferentialMatrix = differentialMatrix**2\n",
    "\n",
    "    # Results in vectors\n",
    "    squaredDistances = squaredDifferentialMatrix.sum(axis=1)\n",
    "    distances = squaredDistances**0.5\n",
    "    \n",
    "    #TODO: NECESITO ENTENDER COMO FUNCIONA ESTE argsort\n",
    "    sortedDistancesIndexes = distances.argsort()\n",
    "    \n",
    "    classCount = {}\n",
    "    \n",
    "    for i in range(k):\n",
    "        label = trainingLabels[sortedDistancesIndexes[i]]\n",
    "        classCount[label] = classCount.get(label,0) + 1\n",
    "        \n",
    "    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test: calculate the error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def calculate():\n",
    "    training, training_labels = loadData('titanic/train.csv')\n",
    "    test, test_labels = loadData('titanic/test.csv')\n",
    "    \n",
    "    np_training = np.array(training)\n",
    "    \n",
    "    print(test_labels)\n",
    "    \n",
    "    # Recorrer todos los test\n",
    "    numberOfTests = len(test)\n",
    "    success = 0\n",
    "    for i in range(numberOfTests):\n",
    "        \n",
    "        ## Ejecutar classify\n",
    "        classifyResult = classify0(test[i], np_training, training_labels, 3)\n",
    "        ## Obtener resultado e incrementar el contador de exitosos\n",
    "        if classifyResult == test_labels[i]:\n",
    "            success += 1\n",
    "\n",
    "    # Calcular el error rate = total / exitosos\n",
    "    return success, success / numberOfTests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-da7f31106a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#REVIEW los ficheros que se cargan en el calculate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-53f95408f7fe>\u001b[0m in \u001b[0;36mcalculate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mclassifyResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m## Obtener resultado e incrementar el contador de exitosos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mclassifyResult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0msuccess\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "calculate()\n",
    "\n",
    "#REVIEW los ficheros que se cargan en el calculate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
